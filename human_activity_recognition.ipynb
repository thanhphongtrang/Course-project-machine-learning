{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model: Human Activity Recognition\n",
    "\n",
    "**Author:** Phong Trang Tran Thanh (Python version)\n",
    "**Date:** January 2025\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Data Description\n",
    "This project examines the Weight Lifting Exercise Data provided by Velloso et al. (2013). They used wearable devices to measure the acceleration of 6 participants to see if the participants were doing the exercises correctly. The accelerometers on the belt, forearm, arm, and dumbbell of 6 participants provide information on the exercise movements. There are 5 classes of the labels: A, B, C, D, and E; only class A is the correct movement while other classes correspond to common mistakes of the training.\n",
    "\n",
    "* **Training Data:** [pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)\n",
    "* **Testing Data:** [pml-testing.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)\n",
    "\n",
    "### The Project Goal\n",
    "This project aims to use data provided by the accelerators to build a supervised learning model that predicts the outcome of correct/incorrect training movements. Two models will be built and evaluated:\n",
    "1.  Random Forest model\n",
    "2.  Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 7.25)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs for the datasets\n",
    "url_train = \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\n",
    "url_test = \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\n",
    "\n",
    "# Load the datasets using pandas\n",
    "# The na_values parameter handles strings that should be treated as NaN\n",
    "training_df = pd.read_csv(url_train, na_values=[\"\", \"NA\", \"#DIV/0!\"])\n",
    "testing_df = pd.read_csv(url_test, na_values=[\"\", \"NA\", \"#DIV/0!\"])\n",
    "\n",
    "print(\"Dimension of the training dataset:\", training_df.shape)\n",
    "print(\"Dimension of the testing dataset:\", testing_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Exploration\n",
    "Let's check the distribution of the target variable `classe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='classe', data=training_df, palette=\"viridis\", order=sorted(training_df['classe'].unique()))\n",
    "plt.title('Number of Observations in Each Class')\n",
    "plt.xlabel('Exercise Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is reasonably balanced, which is good for model training.\n",
    "\n",
    "### Split Data into Training and Validation Sets\n",
    "We will split the original training data into a new training set (80%) and a validation set (20%) to evaluate our models. We use `stratify` to ensure the class distribution is the same in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = training_df.drop('classe', axis=1)\n",
    "y = training_df['classe']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set dimensions:\", X_train.shape)\n",
    "print(\"Validation set dimensions:\", X_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Selection for Modeling\n",
    "\n",
    "We apply a multi-step feature selection process to the training data. The same transformations will be applied to the validation and test sets.\n",
    "\n",
    "### Step 1: Remove columns with a high percentage of NA values\n",
    "First, we remove any column that contains more than 50% NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_percentage = X_train.isnull().sum() / len(X_train)\n",
    "cols_to_drop_na = missing_percentage[missing_percentage > 0.5].index\n",
    "\n",
    "# Drop these columns from all datasets\n",
    "X_train.drop(columns=cols_to_drop_na, inplace=True)\n",
    "X_validation.drop(columns=cols_to_drop_na, inplace=True)\n",
    "testing_df.drop(columns=cols_to_drop_na, inplace=True)\n",
    "\n",
    "print(f\"Dropped {len(cols_to_drop_na)} columns with >50% missing values.\")\n",
    "print(\"New training set dimensions:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Remove descriptive and near-zero variance columns\n",
    "Next, we remove metadata columns and predictors with little to no variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude descriptive columns\n",
    "descriptive_cols = [\"Unnamed: 0\", \"user_name\", \"raw_timestamp_part_1\", \"raw_timestamp_part_2\", \"cvtd_timestamp\", \"new_window\", \"num_window\"]\n",
    "X_train.drop(columns=descriptive_cols, inplace=True)\n",
    "X_validation.drop(columns=descriptive_cols, inplace=True)\n",
    "testing_df.drop(columns=descriptive_cols, inplace=True)\n",
    "\n",
    "# Remove near-zero variance predictors\n",
    "# VarianceThreshold(threshold=0) removes all zero-variance features (i.e., features that have the same value in all samples).\n",
    "selector = VarianceThreshold()\n",
    "selector.fit(X_train)\n",
    "cols_to_keep = X_train.columns[selector.get_support()]\n",
    "\n",
    "X_train = X_train[cols_to_keep]\n",
    "X_validation = X_validation[cols_to_keep]\n",
    "# Ensure the final test set has the same columns\n",
    "testing_df = testing_df[cols_to_keep]\n",
    "\n",
    "print(\"Dropped descriptive columns and zero-variance features.\")\n",
    "print(\"Final training set dimensions after feature selection:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After feature selection, we have reduced the number of predictors to a more manageable and relevant set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Training with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=123, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "rf_predictions = rf_model.predict(X_validation)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy = accuracy_score(y_validation, rf_predictions)\n",
    "print(f\"Random Forest Model Accuracy: {
