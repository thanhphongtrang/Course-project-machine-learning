{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model: Human Activity Recognition\n",
    "\n",
    "**Author:** Phong Trang Tran Thanh (Python version)\n",
    "**Date:** August 7, 2025\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Data Description\n",
    "This project examines the Weight Lifting Exercise Data provided by Velloso et al. (2013). They used wearable devices to measure the acceleration of 6 participants to see if the participants were doing the exercises correctly. The accelerometers on the belt, forearm, arm, and dumbbell of 6 participants provide information on the exercise movements. There are 5 classes of the labels: A, B, C, D, and E; only class A is the correct movement while other classes correspond to common mistakes of the training.\n",
    "\n",
    "* **Training Data:** [pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)\n",
    "* **Testing Data:** [pml-testing.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)\n",
    "\n",
    "### The Project Goal\n",
    "This project aims to use data provided by the accelerators to build a supervised learning model that predicts the outcome of correct/incorrect training movements. Two models will be built and evaluated:\n",
    "1.  Random Forest model\n",
    "2.  Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 7.25)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs for the datasets\n",
    "url_train = \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\n",
    "url_test = \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\n",
    "\n",
    "# Load the datasets using pandas\n",
    "# The na_values parameter handles strings that should be treated as NaN\n",
    "training_df = pd.read_csv(url_train, na_values=[\"\", \"NA\", \"#DIV/0!\"])\n",
    "testing_df = pd.read_csv(url_test, na_values=[\"\", \"NA\", \"#DIV/0!\"])\n",
    "\n",
    "print(\"Dimension of the training dataset:\", training_df.shape)\n",
    "print(\"Dimension of the testing dataset:\", testing_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Exploration\n",
    "Let's check the distribution of the target variable `classe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='classe', data=training_df, palette=\"viridis\", order=sorted(training_df['classe'].unique()))\n",
    "plt.title('Number of Observations in Each Class')\n",
    "plt.xlabel('Exercise Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is reasonably balanced, which is good for model training.\n",
    "\n",
    "### Split Data into Training and Validation Sets\n",
    "We will split the original training data into a new training set (80%) and a validation set (20%) to evaluate our models. We use `stratify` to ensure the class distribution is the same in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = training_df.drop('classe', axis=1)\n",
    "y = training_df['classe']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set dimensions:\", X_train.shape)\n",
    "print(\"Validation set dimensions:\", X_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Selection for Modeling\n",
    "\n",
    "We apply a multi-step feature selection process to the training data. The same transformations will be applied to the validation and test sets.\n",
    "\n",
    "### Step 1: Remove columns with a high percentage of NA values\n",
    "First, we remove any column that contains more than 50% NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_percentage = X_train.isnull().sum() / len(X_train)\n",
    "cols_to_drop_na = missing_percentage[missing_percentage > 0.5].index\n",
    "\n",
    "# Drop these columns from all datasets\n",
    "X_train = X_train.drop(columns=cols_to_drop_na)\n",
    "X_validation = X_validation.drop(columns=cols_to_drop_na)\n",
    "testing_df = testing_df.drop(columns=cols_to_drop_na)\n",
    "\n",
    "print(f\"Dropped {len(cols_to_drop_na)} columns with >50% missing values.\")\n",
    "print(\"New training set dimensions:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Remove descriptive and near-zero variance columns\n",
    "Next, we remove metadata columns and predictors with little to no variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude descriptive columns\n",
    "descriptive_cols = [\"Unnamed: 0\", \"user_name\", \"raw_timestamp_part_1\", \"raw_timestamp_part_2\", \"cvtd_timestamp\", \"new_window\", \"num_window\"]\n",
    "# Ensure these columns exist before trying to drop them\n",
    "cols_to_drop_desc = [col for col in descriptive_cols if col in X_train.columns]\n",
    "X_train = X_train.drop(columns=cols_to_drop_desc)\n",
    "X_validation = X_validation.drop(columns=cols_to_drop_desc)\n",
    "testing_df = testing_df.drop(columns=cols_to_drop_desc)\n",
    "\n",
    "# Remove near-zero variance predictors\n",
    "selector = VarianceThreshold()\n",
    "selector.fit(X_train)\n",
    "cols_to_keep = X_train.columns[selector.get_support()]\n",
    "\n",
    "X_train = X_train[cols_to_keep]\n",
    "X_validation = X_validation[cols_to_keep]\n",
    "testing_df = testing_df[cols_to_keep]\n",
    "\n",
    "print(\"Dropped descriptive columns and zero-variance features.\")\n",
    "print(\"Final training set dimensions after feature selection:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After feature selection, we have reduced the number of predictors to a more manageable and relevant set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Training with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=123, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "rf_predictions = rf_model.predict(X_validation)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy = accuracy_score(y_validation, rf_predictions)\n",
    "print(f\"Random Forest Model Accuracy: {rf_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_validation, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "cm_rf = confusion_matrix(y_validation, rf_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=sorted(y_validation.unique()),\n",
    "            yticklabels=sorted(y_validation.unique()))\n",
    "plt.title('Random Forest Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Training with Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the SVM model\n",
    "print(\"Training SVM model... (This may take a moment)\")\n",
    "svm_model = SVC(random_state=123)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_predictions = svm_model.predict(X_validation)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_validation, svm_predictions)\n",
    "print(f\"SVM Model Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_validation, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for SVM\n",
    "cm_svm = confusion_matrix(y_validation, svm_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=sorted(y_validation.unique()),\n",
    "            yticklabels=sorted(y_validation.unique()))\n",
    "plt.title('SVM Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Prediction on the Test Data\n",
    "\n",
    "The Random Forest model performed exceptionally well. We will use this model to predict the outcomes for the final `testing` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The testing_df has already been preprocessed to have the same columns as X_train\n",
    "# The 'problem_id' column is needed for the final submission but not for prediction\n",
    "final_test_features = testing_df.drop(columns=['problem_id'])\n",
    "final_predictions = rf_model.predict(final_test_features)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "prediction_results = pd.DataFrame({\n",
    "    'problem_id': testing_df['problem_id'],\n",
    "    'predicted_classe': final_predictions\n",
    "})\n",
    "\n",
    "print(\"Predictions on the final 20 test samples:\")\n",
    "print(prediction_results.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
